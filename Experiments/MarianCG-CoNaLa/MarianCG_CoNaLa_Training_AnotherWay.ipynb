{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On0VLQhqDVbn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97Av32IAvNOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f315c2e-bc2f-4bd7-8b0f-e6c9545fcb5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8IdHyYYzK2i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7dM7HDcrX-q"
      },
      "source": [
        "# **Install dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofXr8maUrX-r"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install tensorflow\n",
        "!pip install keras\n",
        "!pip install netron\n",
        "!pip install nltk\n",
        "\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install datasets\n",
        "!pip install nlp\n",
        "!pip install rouge-score\n",
        "#!pip install sacrebleu\n",
        "!pip install git-python\n",
        "!pip install sentencepiece\n",
        "#!pip install torchdata\n",
        "#!pip install transformers\n",
        "!pip install sacrebleu==1.5.1\n",
        "!pip install tree-sitter\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzKO-KzfrX-t"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4IWUUZYvcBH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72,
          "referenced_widgets": [
            "f2e0df7929fd422993bc590426077739",
            "506eb3b3c74e4e5ea6bf5c9e16b508f6",
            "cd2376a8ecef4202911b10d541395ea3",
            "eb63c990e3b145e0af38247f61c4a9bd",
            "584e110fa373470ead55655b42ce0b07",
            "5c0666688ba34d64a18bf2b822214e96",
            "52f3c9b4c07c493cbeeef96c4a25b4a3",
            "d2849346bd074ffa88a5ea793c470a30",
            "2668f75a5b50414ca9f824956bd80043",
            "037969b30b044927b66d0b56c9d089d4",
            "faef2d1c6946448d9186d5cf666cd925"
          ]
        },
        "outputId": "bdf7d3e4-3a0b-4e3a-eb61-e48701ec9ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moving 0 files to the new cache system\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2e0df7929fd422993bc590426077739"
            },
            "application/json": {
              "n": 0,
              "total": 0,
              "elapsed": 0.02220773696899414,
              "ncols": null,
              "nrows": null,
              "prefix": "",
              "ascii": false,
              "unit": "it",
              "unit_scale": false,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1000,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import transformers\n",
        "import datasets\n",
        "from datasets import load_dataset, load_metric\n",
        "import logging\n",
        "from transformers import BertTokenizer, GPT2Tokenizer, GPT2TokenizerFast, EncoderDecoderModel, Trainer, TrainingArguments, BertTokenizerFast\n",
        "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import types\n",
        "import argparse\n",
        "import logging\n",
        "from functools import partial\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import (\n",
        "    BertGenerationConfig,\n",
        "    BertGenerationEncoder,\n",
        "    BertTokenizer,\n",
        "    EncoderDecoderModel,\n",
        "    EncoderDecoderConfig,\n",
        "    GPT2LMHeadModel,\n",
        "    GPT2TokenizerFast,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    get_cosine_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "import sacrebleu\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "#from tensorboardX import SummaryWriter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SugbU_yrX-y"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/models/CodeGeneration/MarianCG-CoNaLa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1oFtehLs3f2",
        "outputId": "183f0d1c-a39e-49f3-c646-bbf0c5a91bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/models/CodeGeneration/MarianCG-CoNaLa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVeSJCQ8UOvn"
      },
      "source": [
        "# **Another way to load data from huggingface**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "raw_dataset = load_dataset(\"AhmedSSoliman/CoNaLa\")"
      ],
      "metadata": {
        "id": "80XDB4WOX0Sk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "bd8dea4a128a469996a09db63302c1f3",
            "9fa2382e35044236979422d3283f88f1",
            "3697e1e87636486097b30f5a24387f26",
            "af8e9ca568aa42818988026201317128",
            "2e5afa06f8ab4dd599d83d661f14efed",
            "bc595c64ba8f4758a7a767bd220dd7b4",
            "ae3c1e9ce9b94232953a89a8fdf09e85",
            "4d337b63ea6b441da75e78a4f36890cb",
            "ff98bd087af1406f8d9db3df7982166e",
            "1d8373efc89940fe96c0b015d048cd22",
            "dda40072bcaf491aa85911d43bb02d3d"
          ]
        },
        "outputId": "41891642-8926-4459-c434-c0aa7f03f585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Using custom data configuration AhmedSSoliman--CoNaLa-91a2c29582ea30f1\n",
            "WARNING:datasets.builder:Reusing dataset csv (/root/.cache/huggingface/datasets/AhmedSSoliman___csv/AhmedSSoliman--CoNaLa-91a2c29582ea30f1/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd8dea4a128a469996a09db63302c1f3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNL3RItYwOSl"
      },
      "source": [
        "train_dataset= raw_dataset[\"train\"]\n",
        "val_dataset = raw_dataset[\"validation\"]\n",
        "test_dataset = raw_dataset[\"test\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nDjW8vlriz5",
        "outputId": "df61fe13-1990-44f9-9282-6d5a30a4efea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['intent', 'snippet'],\n",
              "        num_rows: 11125\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['intent', 'snippet'],\n",
              "        num_rows: 500\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['intent', 'snippet'],\n",
              "        num_rows: 1237\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q41ylHpnj3Ry"
      },
      "source": [
        "# **Prepare the data.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ORxNxB7bINN"
      },
      "outputs": [],
      "source": [
        "encoder_length = 32\n",
        "decoder_length = 32\n",
        "batch_size = 1\n",
        "\n",
        "\n",
        "# map data correctly\n",
        "def map_to_encoder_decoder_inputs(batch):    \n",
        "    inputs = tokenizer(batch[\"intent\"], padding=\"max_length\", truncation=True, max_length=encoder_length)\n",
        "    outputs = tokenizer(batch[\"snippet\"], padding=\"max_length\", truncation=True, max_length=decoder_length)\n",
        "    batch[\"input_ids\"] = inputs.input_ids\n",
        "    batch[\"attention_mask\"] = inputs.attention_mask\n",
        "    batch[\"decoder_input_ids\"] = outputs.input_ids\n",
        "    batch[\"labels\"] = outputs.input_ids.copy()\n",
        "    batch[\"decoder_attention_mask\"] = outputs.attention_mask\n",
        "    \n",
        "    \"\"\"\n",
        "    # complicated list comprehension here because pad_token_id alone is not good enough to know whether label should be excluded or not\n",
        "    batch[\"labels\"] = [\n",
        "        [-100 if mask == 0 else token for mask, token in mask_and_tokens] for mask_and_tokens in [zip(masks, labels) for masks, labels in zip(batch[\"decoder_attention_mask\"], batch[\"labels\"])]\n",
        "    ]\n",
        "    \"\"\"\n",
        "    assert all([len(x) == encoder_length for x in inputs.input_ids])\n",
        "    assert all([len(x) == decoder_length for x in outputs.input_ids])\n",
        "    \n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "060df265a81a4ceb9c6ea0135d7b296f",
            "65cd134d53a9443f91cc47d29ee86013",
            "2912dbe847314451b9130bd7810a6e97",
            "83742a7fc57945bd96a817904ab49ff8",
            "78b10800e41243f3aae8f60aa57b7e4e",
            "6e2e63a23c064fc2bf96cd5ee224f794",
            "d8b7c8018c154ceda41b7f6adac376f4",
            "8fb2bdc552b9420fb19fbef378a0a5db",
            "a08df9eaeecf4b399a3a239026fc2f5e",
            "9ad77993decf41169d8c2f1ec308557a",
            "ed1530dce9e04ca2a70805ecc11996dc"
          ]
        },
        "id": "5p_GH0x5a-hY",
        "outputId": "97bdafc8-84ba-4267-e1ce-308c67ecbaeb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/11125 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "060df265a81a4ceb9c6ea0135d7b296f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# make train dataset ready\n",
        "train_data = train_dataset.map(\n",
        "    map_to_encoder_decoder_inputs, batched=True, batch_size=1, remove_columns=['intent', 'snippet'],\n",
        ")\n",
        "train_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f7fac7d225df494d833dc4ef651fc4bb",
            "f6c93c37e3884b179ca7052deee4f5ac",
            "8f3c8559acd54cd794fa75d295c855dd",
            "4bb3224fb15f4373bc2fcc98c073449d",
            "ce9a8b8fb5bf4fe9aec7125ddb39fac2",
            "47a31587a2494b929fca05e2af6d5a7b",
            "e7a7121545f3439b854ef71df5348f73",
            "5765cdf1761b4fd1b4433ba7df762b79",
            "3f73f0f6645b48059ee5c3cc10086cf5",
            "9d5011e2c83247eda3e6e21263d8f541",
            "023fdbba884e48df8a33fbca3e99ee05"
          ]
        },
        "id": "zUWfkeRqoCdW",
        "outputId": "e3bc376f-69b5-407a-9776-c04e345c1ab6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1237 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7fac7d225df494d833dc4ef651fc4bb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# same for validation dataset\n",
        "val_data = val_dataset.map(\n",
        "    map_to_encoder_decoder_inputs, batched=True, batch_size=1, remove_columns=['intent', 'snippet'],\n",
        ")\n",
        "val_data.set_format(\n",
        "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"decoder_input_ids\", \"decoder_attention_mask\", \"labels\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K2NkAhjo8bOW"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer,\n",
        "                                       max_length=512,padding=True, ####new\n",
        "                                       model = model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6UOP5dA8bOX"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF6rhycZPr2m",
        "outputId": "4b89ddd5-bfe1-419d-e7d7-780922734262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "# set training arguments - these params are not really tuned, feel free to change\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./Marian-Training\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    predict_with_generate=True,\n",
        "    num_train_epochs=10,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    fp16=True,\n",
        "    overwrite_output_dir=True,\n",
        "    learning_rate = 1e-5,\n",
        "    weight_decay=0.01, \n",
        "    warmup_ratio = 0.05,\n",
        "    seed = 1995,\n",
        "    save_total_limit = 2,\n",
        "    load_best_model_at_end = True,\n",
        "    #push_to_hub=True,\n",
        ")\n",
        "#    \n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    compute_metrics=evaluator,\n",
        "    data_collator = data_collator,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset =val_data,\n",
        "       \n",
        ")\n",
        "#    save_total_limit=3,\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Marian-CoNaLa\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "APMeeh2szpJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model()\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74362837-6fd4-45d6-89ee-654a3fcb34d7",
        "id": "VITczVaxu_U9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./Marian-Training\n",
            "Configuration saved in ./Marian-Training/config.json\n",
            "Model weights saved in ./Marian-Training/pytorch_model.bin\n",
            "tokenizer config file saved in ./Marian-Training/tokenizer_config.json\n",
            "Special tokens file saved in ./Marian-Training/special_tokens_map.json\n"
          ]
        }
      ]
    }
  ]
}